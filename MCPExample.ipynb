{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOX4wgdA3wcxwe4NB9FjUO4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GhostScientist/Colab/blob/main/MCPExample.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "_2i_2luY9Bt9"
      },
      "outputs": [],
      "source": [
        "# MCP Demonstration: Standardizing AI Model Interactions\n",
        "# ----------------------------------------------------------\n",
        "\n",
        "# Install required packages\n",
        "!pip install openai anthropic cohere -q\n",
        "\n",
        "# Import necessary libraries\n",
        "import os\n",
        "import json\n",
        "from typing import List, Dict, Any, Optional\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "from anthropic import Anthropic"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add your API keys securely using environment variables\n",
        "# These will only exist for this Colab session - nothing is stored. If you want further control, feel free to make a copy of this notebook for yourself.\n",
        "\n",
        "# OpenAI API key\n",
        "openai_api_key = input(\"Enter your OpenAI API key: \")\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
        "\n",
        "# Anthropic API key (optional)\n",
        "anthropic_api_key = input(\"Enter your Anthropic API key (or press Enter to skip): \")\n",
        "if anthropic_api_key:\n",
        "    os.environ[\"ANTHROPIC_API_KEY\"] = anthropic_api_key"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXp0QH7-9RZb",
        "outputId": "fd255785-33d4-4c8c-9f60-6005e5f0cb38"
      },
      "execution_count": 34,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your OpenAI API key: \n",
            "Enter your Anthropic API key (or press Enter to skip): \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MCPClient:\n",
        "    \"\"\"\n",
        "    Base MCP client that defines a standard interface for interacting with AI models.\n",
        "    This abstraction allows applications to use and share context with different AI providers interchangeably.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, provider_name: str = \"unknown\"):\n",
        "        self.provider_name = provider_name\n",
        "        self.context = []  # Conversation history\n",
        "\n",
        "    def add_message(self, role: str, content: str) -> None:\n",
        "        standard_role = role.lower()\n",
        "        if standard_role not in [\"system\", \"user\", \"assistant\"]:\n",
        "            raise ValueError(f\"Invalid role: {role}. Must be 'system', 'user', or 'assistant'\")\n",
        "\n",
        "        self.context.append({\"role\": standard_role, \"content\": content})\n",
        "\n",
        "    def generate_response(self, prompt: Optional[str] = None,\n",
        "                          system: Optional[str] = None) -> str:\n",
        "        \"\"\"\n",
        "        Generate a response using the current context\n",
        "\n",
        "        Args:\n",
        "            prompt: Optional new user message to add before generating a response\n",
        "            system: Optional system message to set or update\n",
        "\n",
        "        Returns:\n",
        "            The AI model's response text\n",
        "        \"\"\"\n",
        "        raise NotImplementedError(\"Subclasses must implement this method\")\n",
        "\n",
        "    def get_context(self) -> List[Dict[str, str]]:\n",
        "        \"\"\"Get the current conversation context in standardized format\"\"\"\n",
        "        return self.context.copy()\n",
        "\n",
        "    def set_context(self, context: List[Dict[str, str]]) -> None:\n",
        "        \"\"\"Set the conversation context, enabling context transfer between providers\"\"\"\n",
        "        self.context = context.copy()\n",
        "\n",
        "    def clear_context(self) -> None:\n",
        "        \"\"\"Clear the conversation context\"\"\"\n",
        "        self.context = []"
      ],
      "metadata": {
        "id": "12guG2AB9Xvg"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class OpenAIMCPClient(MCPClient):\n",
        "    \"\"\"OpenAI-specific implementation of the MCP client\"\"\"\n",
        "\n",
        "    def __init__(self, api_key: Optional[str] = None, model: str = \"gpt-4o-mini\"):\n",
        "        super().__init__(provider_name=\"openai\")\n",
        "        self.model = model\n",
        "\n",
        "        # Use provided API key or get from environment variable\n",
        "        if api_key:\n",
        "            self.client = OpenAI(api_key=api_key)\n",
        "        else:\n",
        "            self.client = OpenAI()\n",
        "\n",
        "    def generate_response(self, prompt: Optional[str] = None,\n",
        "                          system: Optional[str] = None) -> str:\n",
        "        # Special handling for models that don't support system role\n",
        "        models_without_system_role = [\"o1-mini\"]\n",
        "        supports_system = self.model not in models_without_system_role\n",
        "\n",
        "        # Update system message if provided and supported\n",
        "        if system and supports_system:\n",
        "            # Check if we already have a system message\n",
        "            has_system = any(msg[\"role\"] == \"system\" for msg in self.context)\n",
        "\n",
        "            if has_system:\n",
        "                # Update existing system message\n",
        "                for i, msg in enumerate(self.context):\n",
        "                    if msg[\"role\"] == \"system\":\n",
        "                        self.context[i] = {\"role\": \"system\", \"content\": system}\n",
        "                        break\n",
        "            else:\n",
        "                # Add system message at the beginning\n",
        "                self.context.insert(0, {\"role\": \"system\", \"content\": system})\n",
        "        elif system and not supports_system:\n",
        "            # For models without system role support, we'll prepend to the user message\n",
        "            prompt = f\"System instruction: {system}\\n\\nUser query: {prompt}\"\n",
        "\n",
        "        # Add new user message if provided\n",
        "        if prompt:\n",
        "            self.add_message(\"user\", prompt)\n",
        "\n",
        "        # Prepare messages for API call based on model capabilities\n",
        "        api_messages = self.context.copy()\n",
        "        if not supports_system:\n",
        "            # Filter out system messages for models that don't support them\n",
        "            api_messages = [msg for msg in api_messages if msg[\"role\"] != \"system\"]\n",
        "\n",
        "        # Make the API call using OpenAI's format\n",
        "        try:\n",
        "            response = self.client.chat.completions.create(\n",
        "                model=self.model,\n",
        "                messages=api_messages\n",
        "            )\n",
        "\n",
        "            # Extract and add the response to context\n",
        "            assistant_message = response.choices[0].message.content\n",
        "            self.add_message(\"assistant\", assistant_message)\n",
        "\n",
        "            return assistant_message\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"Error: {str(e)}\""
      ],
      "metadata": {
        "id": "Uew_VhBh9bED"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openai_client = OpenAIMCPClient(model=\"gpt-4o-mini\")\n",
        "\n",
        "response = openai_client.generate_response(\n",
        "    prompt=\"What is the Model Context Protocol?\",\n",
        "    system=\"You are a helpful AI assistant that explains technical concepts clearly and concisely.\"\n",
        ")\n",
        "\n",
        "print(f\"Response from {openai_client.provider_name} ({openai_client.model}):\\n\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bow_HcpR9dSK",
        "outputId": "bd2c3207-5d04-4d86-bdbf-80d4e9871bf3"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response from openai (gpt-4o-mini):\n",
            "\n",
            "The Model Context Protocol (MCP) is a framework used primarily in artificial intelligence and machine learning to enhance the interactions between models and their environments. It provides a structured way for models to understand and adapt to the context in which they operate, allowing for more effective decision-making and action.\n",
            "\n",
            "Key components of the Model Context Protocol typically include:\n",
            "\n",
            "1. **Context Representation**: This refers to the information about the environment, constraints, goals, and other relevant factors that the model needs to consider. This could include data about user preferences, situational variables, or external conditions.\n",
            "\n",
            "2. **Adaptation Mechanism**: MCP includes strategies for models to adjust their behavior based on the context they are given. This might involve modifying parameters, switching between different algorithms, or changing the way information is processed.\n",
            "\n",
            "3. **Feedback Loop**: The protocol often incorporates mechanisms for feedback, allowing models to learn from the outcomes of their actions and to refine their understanding of the context over time.\n",
            "\n",
            "4. **Interoperability**: A key feature of MCP is its ability to facilitate communication and cooperation among multiple models or systems, enabling them to share contextual information and jointly solve problems.\n",
            "\n",
            "MCP is particularly relevant in areas like natural language processing, recommender systems, and robotics, where understanding the context can significantly influence performance and user satisfaction.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class AnthropicMCPClient(MCPClient):\n",
        "    \"\"\"Anthropic-specific implementation of the MCP client\"\"\"\n",
        "\n",
        "    def __init__(self, api_key: Optional[str] = None, model: str = \"claude-3-5-sonnet-20241022\"):\n",
        "        super().__init__(provider_name=\"anthropic\")\n",
        "        self.model = model\n",
        "\n",
        "        # Use provided API key or get from environment variable\n",
        "        if api_key:\n",
        "            self.client = Anthropic(api_key=api_key)\n",
        "        else:\n",
        "            self.client = Anthropic()\n",
        "\n",
        "    def generate_response(self, prompt: Optional[str] = None,\n",
        "                          system: Optional[str] = None) -> str:\n",
        "        \"\"\"Generate a response using Anthropic's API\"\"\"\n",
        "\n",
        "        # Add new user message if provided\n",
        "        if prompt:\n",
        "            self.add_message(\"user\", prompt)\n",
        "\n",
        "        # Convert our context to Anthropic's format\n",
        "        # We'll only use the user/assistant messages (not system)\n",
        "        anthropic_messages = []\n",
        "\n",
        "        for msg in self.context:\n",
        "            if msg[\"role\"] != \"system\":  # Skip system messages\n",
        "                role = \"user\" if msg[\"role\"] == \"user\" else \"assistant\"\n",
        "                anthropic_messages.append({\"role\": role, \"content\": msg[\"content\"]})\n",
        "\n",
        "        # If we somehow have no messages, add a default\n",
        "        if not anthropic_messages:\n",
        "            anthropic_messages = [{\"role\": \"user\", \"content\": \"Hello\"}]\n",
        "\n",
        "        try:\n",
        "            # Make the API call using only the required parameters mentioned in the error\n",
        "            response = self.client.messages.create(\n",
        "                model=self.model,\n",
        "                max_tokens=1024,\n",
        "                messages=anthropic_messages\n",
        "            )\n",
        "\n",
        "            # If we have a system message and it succeeded without it, we'll note that\n",
        "            has_system = any(msg[\"role\"] == \"system\" for msg in self.context)\n",
        "            if has_system or system:\n",
        "                print(\"Note: System message was ignored for Anthropic API call\")\n",
        "\n",
        "            # Extract and add the response to context\n",
        "            assistant_message = response.content[0].text\n",
        "            self.add_message(\"assistant\", assistant_message)\n",
        "\n",
        "            return assistant_message\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"Error: {str(e)}\""
      ],
      "metadata": {
        "id": "2TsYmA599koo"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_anthropic_direct():\n",
        "    \"\"\"Test Anthropic API directly without the MCP wrapper\"\"\"\n",
        "    from anthropic import Anthropic\n",
        "\n",
        "    client = Anthropic()\n",
        "\n",
        "    try:\n",
        "        # Direct API call using the documented structure\n",
        "        response = client.messages.create(\n",
        "            model=\"claude-3-5-sonnet-20241022\",\n",
        "            max_tokens=1024,\n",
        "            messages=[\n",
        "                {\"role\": \"user\", \"content\": \"Hello, please respond with one word: TESTING\"}\n",
        "            ]\n",
        "        )\n",
        "        print(\"API call successful!\")\n",
        "        print(f\"Response: {response.content[0].text}\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"API call failed: {str(e)}\")\n",
        "        return False\n",
        "\n",
        "test_result = test_anthropic_direct()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LjovdYO2_BTq",
        "outputId": "c094b167-7f3d-42b5-bcf2-edb65823e635"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "API call successful!\n",
            "Response: TESTING\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_sentiment(text: str, client: MCPClient) -> str:\n",
        "    \"\"\"\n",
        "    Analyze the sentiment of text using any MCP-compatible client\n",
        "\n",
        "    Args:\n",
        "        text: The text to analyze\n",
        "        client: Any MCP-compatible client\n",
        "\n",
        "    Returns:\n",
        "        The sentiment analysis result\n",
        "    \"\"\"\n",
        "\n",
        "    client.clear_context()\n",
        "\n",
        "\n",
        "    system_prompt = \"\"\"\n",
        "    You are a sentiment analysis assistant. Analyze the sentiment of the provided text\n",
        "    and respond with exactly one word: POSITIVE, NEGATIVE, or NEUTRAL.\n",
        "    Provide no other text in your response.\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    result = client.generate_response(\n",
        "        prompt=f\"Analyze the sentiment of this text: {text}\",\n",
        "        system=system_prompt\n",
        "    )\n",
        "\n",
        "    return result\n",
        "\n",
        "test_texts = [\n",
        "    \"I absolutely love this product! It's the best purchase I've made all year.\",\n",
        "    \"The service was terrible and the staff was rude. I'm never going back.\",\n",
        "    \"The movie was okay. It had some good moments but also some boring parts.\"\n",
        "]\n",
        "\n",
        "# Uncomment either OpenAI or Anthropic to test.\n",
        "\n",
        "# Test with OpenAI\n",
        "#print(\"SENTIMENT ANALYSIS WITH OPENAI:\\n\")\n",
        "#for text in test_texts:\n",
        "#    sentiment = analyze_sentiment(text, openai_client)\n",
        "#    print(f\"Text: {text}\")\n",
        "#    print(f\"Sentiment: {sentiment}\\n\")\n",
        "\n",
        "\n",
        "anthropic_client = AnthropicMCPClient()\n",
        "print(\"\\nSENTIMENT ANALYSIS WITH ANTHROPIC:\\n\")\n",
        "for text in test_texts:\n",
        "     sentiment = analyze_sentiment(text, anthropic_client)\n",
        "     print(f\"Text: {text}\")\n",
        "     print(f\"Sentiment: {sentiment}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BW2t_5s9lRi",
        "outputId": "8e8fdd4e-a3be-42ea-a9c4-baedd3300650"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "SENTIMENT ANALYSIS WITH ANTHROPIC:\n",
            "\n",
            "Note: System message was ignored for Anthropic API call\n",
            "Text: I absolutely love this product! It's the best purchase I've made all year.\n",
            "Sentiment: This text has a very positive sentiment. The use of enthusiastic language (\"absolutely love\"), superlatives (\"best\"), and exclamation points indicates strong positive emotions. The speaker expresses complete satisfaction with their purchase.\n",
            "\n",
            "Note: System message was ignored for Anthropic API call\n",
            "Text: The service was terrible and the staff was rude. I'm never going back.\n",
            "Sentiment: This text has a strongly negative sentiment. The use of words like \"terrible\" and \"rude\" express clear dissatisfaction, and the statement \"never going back\" reinforces the negative experience and shows complete rejection of the establishment.\n",
            "\n",
            "Note: System message was ignored for Anthropic API call\n",
            "Text: The movie was okay. It had some good moments but also some boring parts.\n",
            "Sentiment: This text expresses a mixed or neutral sentiment. The words \"okay\" and phrases like \"some good moments but also some boring parts\" indicate neither strong positive nor negative feelings, suggesting a balanced or lukewarm reaction to the movie.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# FYI: This example will only work if you have both API keys set up.\n",
        "\n",
        "def demonstrate_context_transfer():\n",
        "\n",
        "    openai_client = OpenAIMCPClient()\n",
        "    openai_client.clear_context()\n",
        "\n",
        "    print(\"Starting conversation with OpenAI:\\n\")\n",
        "\n",
        "    openai_client.generate_response(\n",
        "        system=\"You are a helpful assistant that provides concise information about planets.\",\n",
        "        prompt=\"Tell me about Mars.\"\n",
        "    )\n",
        "\n",
        "    print(f\"[OpenAI]: {openai_client.context[-1]['content']}\\n\")\n",
        "\n",
        "    openai_client.generate_response(prompt=\"What about its moons?\")\n",
        "    print(f\"[OpenAI]: {openai_client.context[-1]['content']}\\n\")\n",
        "\n",
        "    conversation_context = openai_client.get_context()\n",
        "\n",
        "    try:\n",
        "        anthropic_client = AnthropicMCPClient()\n",
        "\n",
        "        anthropic_client.set_context(conversation_context)\n",
        "\n",
        "        print(\"Continuing conversation with Anthropic:\\n\")\n",
        "        response = anthropic_client.generate_response(\n",
        "            prompt=\"How does gravity on Mars compare to Earth?\"\n",
        "        )\n",
        "\n",
        "        print(f\"[Anthropic]: {response}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Couldn't test with Anthropic: {str(e)}\")\n",
        "        print(\"You may need to set up your Anthropic API key to run this example.\")\n",
        "\n",
        "\n",
        "demonstrate_context_transfer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gp6e_oyz9ssh",
        "outputId": "a91bbba3-454a-4b19-a662-03c7c1c52b07"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting conversation with OpenAI:\n",
            "\n",
            "[OpenAI]: Mars is the fourth planet from the Sun in our solar system and is often called the \"Red Planet\" due to its reddish appearance, which is a result of iron oxide (rust) on its surface. Here are some key facts about Mars:\n",
            "\n",
            "1. **Size and Structure**: Mars has a diameter of about 6,779 kilometers (4,212 miles), making it about half the size of Earth. It has a thin atmosphere, composed mostly of carbon dioxide.\n",
            "\n",
            "2. **Moons**: Mars has two small moons, Phobos and Deimos, which are thought to be captured asteroids.\n",
            "\n",
            "3. **Surface Features**: The planet features the largest volcano in the solar system, Olympus Mons, and a massive canyon system, Valles Marineris. It also has polar ice caps made of water and carbon dioxide.\n",
            "\n",
            "4. **Water**: Mars has evidence of past water flows and currently has water ice beneath its surface, with seasonal dark streaks suggesting possible briny liquid water flows.\n",
            "\n",
            "5. **Exploration**: Mars has been explored by numerous spacecraft, including rovers like Curiosity and Perseverance, which are studying its geology and searching for signs of past life.\n",
            "\n",
            "6. **Conditions**: The surface temperature varies widely, averaging around -80 degrees Fahrenheit (-62 degrees Celsius). It experiences dust storms that can cover the entire planet.\n",
            "\n",
            "7. **Potential for Life**: Mars has long been a target for the search for extraterrestrial life due to its past conditions that may have been suitable for life.\n",
            "\n",
            "Mars continues to be a focus of scientific exploration, with future manned missions planned by several space agencies.\n",
            "\n",
            "[OpenAI]: Mars has two small moons, Phobos and Deimos. Here are some details about each:\n",
            "\n",
            "### Phobos\n",
            "1. **Size and Shape**: Phobos is the larger of Mars' two moons, with a diameter of about 22 kilometers (14 miles). It has a irregular shape, resembling a potato more than a sphere.\n",
            "\n",
            "2. **Orbit**: It orbits Mars very closely, at an average distance of about 6,000 kilometers (3,700 miles) above the surface. It takes just about 7 hours and 39 minutes to complete one orbit, which is shorter than a Martian day.\n",
            "\n",
            "3. **Surface Features**: The surface of Phobos is covered with craters, the largest being Stickney Crater. Its low gravity means that it has a very weak atmosphere and constantly shed material.\n",
            "\n",
            "4. **Fate**: Phobos is slowly spiraling inward towards Mars and is expected to either crash into the planet or break apart to form a ring system in about 50 million years.\n",
            "\n",
            "### Deimos\n",
            "1. **Size and Shape**: Deimos is smaller than Phobos, with a diameter of about 12 kilometers (7.5 miles). Like Phobos, it also has an irregular, potato-like shape.\n",
            "\n",
            "2. **Orbit**: Deimos orbits at a greater distance than Phobos, approximately 23,460 kilometers (14,580 miles) from the Martian surface. It takes about 30.3 hours to complete one orbit, which means it rises in the east and sets in the west.\n",
            "\n",
            "3. **Surface Features**: Deimos' surface is smoother than that of Phobos, covered with a layer of fine dust and regolith, giving it a less cratered appearance.\n",
            "\n",
            "4. **Origin**: Both moons are thought to be captured asteroids from the asteroid belt between Mars and Jupiter due to their composition and shape.\n",
            "\n",
            "### Overall\n",
            "Both moons are of significant interest to scientists studying the history and evolution of the Martian system. While they are small and irregularly shaped compared to Earth's moon, their proximity to Mars and unique characteristics make them valuable targets for future exploration.\n",
            "\n",
            "Continuing conversation with Anthropic:\n",
            "\n",
            "Note: System message was ignored for Anthropic API call\n",
            "[Anthropic]: Gravity on Mars is approximately 38% of Earth's gravity (or about one-third). Here's a detailed comparison:\n",
            "\n",
            "Earth's Gravity:\n",
            "- 9.81 meters per second squared (m/s²)\n",
            "- 1 g\n",
            "\n",
            "Mars' Gravity:\n",
            "- 3.72 meters per second squared (m/s²)\n",
            "- 0.38 g\n",
            "\n",
            "This means that:\n",
            "1. A person who weighs 100 pounds (45 kg) on Earth would weigh about 38 pounds (17 kg) on Mars\n",
            "2. Objects fall more slowly on Mars\n",
            "3. It's easier to jump higher and throw things farther on Mars\n",
            "4. The lower gravity affects how things work and behave:\n",
            "   - Fluid dynamics\n",
            "   - Plant growth\n",
            "   - Human physiology\n",
            "   - Construction and engineering\n",
            "\n",
            "The reduced gravity on Mars presents both advantages and challenges for potential human colonization:\n",
            "\n",
            "Advantages:\n",
            "- Easier to move heavy objects\n",
            "- Less structural support needed for buildings\n",
            "- Lower launch energy needed to leave Mars\n",
            "\n",
            "Challenges:\n",
            "- Human health issues (muscle atrophy, bone loss)\n",
            "- Different design requirements for equipment and vehicles\n",
            "- Adapting Earth-based technologies to work in lower gravity\n",
            "\n",
            "This difference in gravity is an important consideration in planning Mars missions and potential colonization efforts.\n"
          ]
        }
      ]
    }
  ]
}